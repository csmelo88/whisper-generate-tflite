{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d147f66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Suporte\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Audio\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperFeatureExtractor, TFWhisperForConditionalGeneration, WhisperTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb8dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an account in huggingface, generate a token and paste here:\n",
    "use_auth_token='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e671280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper model\n",
    "lang = \"portuguese\"\n",
    "model_name = \"openai/whisper-base\" # Choose: tiny, base, small, medium, or large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b69da3a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name , token=use_auth_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d07f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WhisperTokenizer.from_pretrained(model_name, language=lang, task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de5f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor(feature_extractor, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a590fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Suporte\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFWhisperForConditionalGeneration.\n",
      "\n",
      "All the weights of TFWhisperForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFWhisperForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFWhisperForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5997e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=lang, task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc4830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "#ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "\n",
    "# https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0\n",
    "ds = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"pt\", split=\"validation\", trust_remote_code=True)\n",
    "# Original sampling in 48000. Must be converted to 16000\n",
    "ds = ds.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9378bc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Viva então, sei para ir buscar o caminhão, que estava no interior da casa.\n",
      " Onde é o casa?\n",
      " Em septembro, que em tempo trico, que ela se lembrava.\n",
      " mais se acorda como lei.\n",
      " Este cavalo tem mais de um cavalo de potência.\n",
      " Seu amor à vida é o amor de viva.\n",
      " Boa vista do Ingram.\n",
      " Essa dasche está sempre fazendo.\n",
      " Milévia, até a estação de três interessedadores.\n",
      " Capitamos intuitivamente os símbolos linguísticos.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    inputs = feature_extractor(\n",
    "        ds[i][\"audio\"][\"array\"], sampling_rate=ds[i][\"audio\"][\"sampling_rate\"], return_tensors=\"tf\"\n",
    "    )\n",
    "    input_features = inputs.input_features\n",
    "    \n",
    "    # Generating Transcription\n",
    "    generated_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n",
    "    #transcription = processor.tokenizer.decode(generated_ids[0])\n",
    "    #print(transcription)\n",
    "    transcription = processor.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "    print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29dee488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Suporte\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "INFO:tensorflow:Assets written to: content/tf_whisper_saved\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: content/tf_whisper_saved\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('content/tf_whisper_saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec6e16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'content/tf_whisper_saved'\n",
    "tflite_model_path = 'whisper-base-pt.tflite'\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a1db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
